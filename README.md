<div align="center">
  <h1>patina-bot: Lightweight AI Agent Framework</h1>
  <p>
    <img src="https://img.shields.io/badge/rust-1.75+-orange" alt="Rust">
    <img src="https://img.shields.io/badge/status-alpha-yellow" alt="Status">
    <img src="https://img.shields.io/badge/license-MIT-green" alt="License">
  </p>
  <p><strong>Ultra-lightweight AI agent framework in Rust â€” 10-50x lower memory, single static binary, no runtime dependencies</strong></p>
</div>

---

## ğŸš€ Why Rust?

**patina-bot** is a Rust-based AI agent framework inspired by the nanobot concept, designed for:

- **ğŸª¶ Minimal footprint**: ~30MB memory (vs Python's ~200-400MB)
- **âš¡ Fast startup**: ~50-100ms (vs Python's ~2-3s)
- **ğŸ“¦ Single binary**: No Python runtime, pip, or venv needed
- **ğŸ”’ Type safety**: Catch bugs at compile time
- **ğŸŒ Local-first**: Prioritizes Ollama and local inference by default

**Current Status**: Core CLI + gateway are working, including Telegram polling, cron/heartbeat services, and markdown skill loading.

---

## ğŸ“¦ Install

### From Source (Recommended)

```bash
git clone https://github.com/HKUDS/nanobot.git
cd nanobot/patina-bot
cargo build --release
```

Binary will be at `target/release/patina`.

### Using Cargo Install

```bash
cargo install --path patina-bot/crates/patina-cli
```

---

## ğŸš€ Quick Start

### 1. Initialize

```bash
patina onboard
```

This creates config and workspace files (default path: `~/.patina/config.json`).
If `./config.json` exists in your current directory, that local file is used instead.

### 2. Configure

Edit the config file selected by priority:
1. `--config` CLI argument
2. `./config.json`
3. `~/.patina/config.json`

**For local-first (Ollama, recommended):**

```json
{
  "providers": {
    "ollama": {
      "apiBase": "http://localhost:11434"
    }
  },
  "agents": {
    "defaults": {
      "model": "llama3.2",
      "maxTokens": 4096,
      "temperature": 0.7
    }
  }
}
```

**For cloud providers (OpenAI-compatible):**

```json
{
  "providers": {
    "openai": {
      "apiKey": "sk-...",
      "apiBase": "https://api.openai.com/v1"
    }
  },
  "agents": {
    "defaults": {
      "model": "gpt-4"
    }
  }
}
```

**For Anthropic (Claude):**

```json
{
  "providers": {
    "anthropic": {
      "apiKey": "sk-ant-..."
    }
  },
  "agents": {
    "defaults": {
      "model": "claude-sonnet-4-5-20250514"
    }
  }
}
```

### 3. Chat

```bash
# Single message
patina agent -m "What is 2+2?"

# Interactive mode
patina agent
```

---

## ğŸ—ï¸ Architecture

patina-bot is a Cargo workspace with 4 crates:

```
patina-bot/
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ patina-core/      # Agent loop, tools, session management
â”‚   â”œâ”€â”€ patina-config/    # Configuration schema and loading
â”‚   â”œâ”€â”€ patina-channels/  # Channel adapters (Telegram, etc.)
â”‚   â””â”€â”€ patina-cli/       # CLI binary
â”œâ”€â”€ Cargo.toml             # Workspace manifest
â””â”€â”€ README.md
```

### Message Flow

```
User Input
    â†“
[ CLI / Channel Listener ]
    â†“
[ Message Bus (tokio mpsc/broadcast) ]
    â†“
[ Agent Loop ] â†â†’ [ LLM Provider (rig-core) ]
    â†“                      â†“
[ Tool Registry ]    [ Tool Execution ]
    â†“                      â†“
[ Session Manager (JSONL) ]
    â†“
[ Response ] â†’ User
```

---

## âœ¨ Features

### âœ… Implemented (Phase 1 Complete)

| Feature | Status | Notes |
|---------|--------|-------|
| **Config Loading** | âœ… | JSON with camelCase, Python-compatible |
| **Session Persistence** | âœ… | JSONL format, interchangeable with Python |
| **Message Bus** | âœ… | Tokio channels (mpsc/broadcast) |
| **LLM Integration** | âœ… | Via rig-core 0.30 |
| **Provider Support** | âœ… | Ollama (default), OpenAI, Anthropic, OpenRouter, DeepSeek, Groq, Gemini |
| **Tool System** | âœ… | Registry + dynamic dispatch |
| **File Tools** | âœ… | read_file, write_file, edit_file, list_dir |
| **Shell Tool** | âœ… | exec_command with timeout |
| **Web Tools** | âœ… | web_search (Brave), web_fetch |
| **Agent Loop** | âœ… | LLM â†” tool iteration with max iterations |
| **Context Builder** | âœ… | System prompt + message history |
| **CLI** | âœ… | Interactive mode (rustyline REPL) |
| **Workspace** | âœ… | AGENTS.md, SOUL.md, USER.md support |

### âœ… Delivered (Phase 2-3)

| Feature | Status | Priority | Notes |
|---------|--------|----------|-------|
| **Memory Consolidation** | âœ… Basic | HIGH | Session-aware consolidation path is wired in |
| **Skills Loader** | âœ… | HIGH | YAML frontmatter, workspace override, builtin fallback |
| **Subagent System** | âœ… | MEDIUM | Background task spawning via `spawn` tool |
| **Cron Service** | âœ… | MEDIUM | Integrated service + CLI management commands |
| **Heartbeat** | âœ… | LOW | Background heartbeat loop in gateway |
| **Telegram Channel** | âœ… | HIGH | Long polling, media handling, markdown conversion |
| **Gateway Mode** | âœ… | HIGH | Multi-channel routing via `patina serve` |
| **Message Tool** | âœ… | MEDIUM | Sends notifications via active channel bus |

### ğŸ“‹ Planned (Phase 4+)

| Feature | Priority | Notes |
|---------|----------|-------|
| **Discord Channel** | MEDIUM | WebSocket integration via twilight/serenity |
| **Slack Channel** | MEDIUM | Socket Mode via slack-morphism |
| **Email Channel** | LOW | IMAP/SMTP polling |
| **WhatsApp Channel** | LOW | Bridge complexity |
| **Cron CLI Commands** | LOW | list/add/remove/enable/run |
| **Vector Memory** | FUTURE | Semantic search with embedded DB |
| **WASM Plugin System** | FUTURE | Hot-loadable native tools |

---

## ğŸ”§ Configuration

Config file location (checked in order):
1. `--config` CLI argument
2. `./config.json`
3. `~/.patina/config.json`

### Full Config Schema

<details>
<summary>Expand to see full config.json structure</summary>

```json
{
  "agents": {
    "defaults": {
      "workspace": "~/.patina/workspace",
      "model": "gpt-oss-20b-GGUF",
      "maxTokens": 8192,
      "temperature": 0.7,
      "maxToolIterations": 20,
      "memoryWindow": 50,
    }
  },
  "channels": {
    "telegram": {
      "enabled": false,
      "token": "",
      "allowFrom": [],
      "proxy": null
    }
  },
  "providers": {
    "ollama": {
      "apiBase": "http://localhost:11434"
    },
    "anthropic": {
      "apiKey": ""
    },
    "openai": {
      "apiKey": ""
    },
    "openrouter": {
      "apiKey": ""
    },
    "deepseek": {
      "apiKey": ""
    },
    "groq": {
      "apiKey": ""
    },
    "gemini": {
      "apiKey": ""
    }
  },
  "tools": {
    "restrictToWorkspace": false,
    "exec": {
      "timeoutSecs": 60
    },
    "web": {
      "search": {
        "apiKey": "",
        "maxResults": 5
      }
    }
  },
  "gateway": {
    "host": "0.0.0.0",
    "port": 18790
  },
  "heartbeat": {
    "enabled": false,
    "intervalSecs": 1800
  },
  "transcription": {
    "mode": "auto",
    "modelPath": "~/.patina/models/parakeet-tdt",
    "executionProvider": "cpu",
    "autoDownload": true
  }
}
```

</details>

### Provider Priority

Provider selection is currently:

1. **OpenAI-compatible** when `providers.openai.apiBase` is set
2. **OpenRouter key prefix** (`sk-or-*`) when present
3. **Auto-detect by model name**:
   - `claude-*` â†’ Anthropic
   - `gpt-*`, `o1-*`, `o3-*`, `o4-*` â†’ OpenAI
   - `deepseek-*` â†’ DeepSeek
   - `gemini-*` â†’ Gemini
   - Models with `/` â†’ OpenRouter
4. **OpenRouter fallback** when its API key is configured
5. **Ollama fallback** (local default)

### Security

| Option | Default | Description |
|--------|---------|-------------|
| `tools.restrictToWorkspace` | `false` | When `true`, restricts file/shell tools to workspace directory |
| `channels.*.allowFrom` | `[]` | Whitelist of user IDs (empty = allow all) |

---

## ğŸ–¥ï¸ CLI Reference

```bash
# Initialize config and workspace
patina onboard

# Initialize without prompts
patina onboard --non-interactive

# Interactive chat (REPL)
patina agent

# Single message
patina agent -m "Hello, world!"

# Custom session ID
patina agent -s "my-session"

# Custom config path
patina -c /path/to/config.json agent

# Interrupt a running session
patina interrupt --session "cli:interactive"

# Start gateway (receive messages from channels)
patina serve

# Show status
patina status

# Cron management
patina cron list
patina cron add --name morning --message "Daily check-in" --every 3600
patina cron run <job_id>

# Channel status
patina channels status
```

### Build Commands

```bash
# Build all crates
cargo build

# Build release (optimized)
cargo build --release

# Run tests
cargo test

# Run with logging
RUST_LOG=debug cargo run --bin patina -- agent
```

---

## ğŸ“¡ Channels

### Telegram

**Status**: âœ… Implemented

**Current Features**:
- Long polling (no webhook needed)
- Markdown-to-HTML conversion with table support
- Thread/topic support (separate contexts per topic)
- Voice/photo/document handling
- Typing indicators
- Proxy support
- `/new`, `/help` slash commands

**Configuration**:

```json
{
  "channels": {
    "telegram": {
      "enabled": true,
      "token": "YOUR_BOT_TOKEN",
      "allowFrom": ["USER_ID"],
      "proxy": "socks5://127.0.0.1:1080"
    }
  }
}
```

**Setup**:
1. Create bot via @BotFather
2. Copy token to config
3. Run `patina serve`

### Other Channels

| Channel | Status | Crate | Priority |
|---------|--------|-------|----------|
| Discord | ğŸ“‹ Planned | twilight/serenity | Medium |
| Slack | ğŸ“‹ Planned | slack-morphism | Medium |
| WhatsApp | ğŸ“‹ Planned | TBD | Low |
| Email | ğŸ“‹ Planned | async-imap + lettre | Low |

All channels implement the `Channel` trait for drop-in compatibility.

---

## ğŸ› ï¸ Tools

Tools are registered at runtime and exposed to the LLM for execution.

### Built-in Tools

| Tool | Status | Description |
|------|--------|-------------|
| `read_file` | âœ… | Read file contents |
| `write_file` | âœ… | Write/overwrite file |
| `edit_file` | âœ… | Replace text in file |
| `list_dir` | âœ… | List directory contents |
| `exec_command` | âœ… | Execute shell command |
| `web_search` | âœ… | Brave Search API |
| `web_fetch` | âœ… | Fetch URL content |
| `message` | âœ… | Send to channel/user |
| `spawn` | âœ… | Launch background subagent |
| `cron` | âœ… | Schedule/list/remove/trigger jobs |

### Tool Trait

All tools implement:

```rust
#[async_trait]
pub trait Tool: Send + Sync {
    fn name(&self) -> &str;
    fn description(&self) -> &str;
    fn parameters_schema(&self) -> serde_json::Value;
    async fn execute(&self, params: serde_json::Value) -> Result<String>;
}
```

### Workspace Restriction

When `tools.restrictToWorkspace: true`:
- All file/shell operations confined to workspace directory
- Prevents path traversal attacks
- Recommended for production deployments

---

## ğŸ“š Skills

**Status**: âœ… Implemented (markdown skills)

Skills are markdown files with YAML frontmatter that extend agent capabilities.

### Current Architecture

**Layer 1: Markdown Skills** (preferred)
- `SKILL.md` with YAML frontmatter
- LLM interprets instructions
- No compilation needed
- **Python-compatible** â€” existing skills work unchanged

**Layer 2: Bundled Scripts**
- Python/Bash scripts in `scripts/` directory
- Executed via `exec_command` tool
- Language-agnostic subprocess execution

**Layer 3: WASM Plugins** (future)
- Native tool plugins
- Sandboxed execution
- Hot-loadable at runtime
- Language-agnostic (Rust, Go, C, AssemblyScript)

### Example Skill Structure

```
~/.patina/skills/my-skill/
â”œâ”€â”€ SKILL.md          # Instructions + YAML metadata
â”œâ”€â”€ scripts/          # Optional helper scripts
â”‚   â””â”€â”€ helper.py
â”œâ”€â”€ references/       # Optional docs (loaded on-demand)
â””â”€â”€ assets/           # Optional files
```

---

## ğŸ’¾ Sessions

Sessions are stored as JSONL files at `~/.patina/sessions/{session_key}.jsonl`.

### Format

**Line 1** (metadata):
```json
{"_type":"metadata","created_at":"2025-02-14T10:00:00Z","updated_at":"2025-02-14T10:30:00Z","metadata":{},"last_consolidated":0}
```

**Subsequent lines** (messages):
```json
{"role":"user","content":"Hello","timestamp":"2025-02-14T10:01:00Z"}
{"role":"assistant","content":"Hi!","timestamp":"2025-02-14T10:01:05Z","tools_used":["read_file"]}
```

### Session Format

Sessions use a simple JSONL format:
- Line 1: Metadata (created_at, updated_at, etc.)
- Subsequent lines: Messages with role, content, timestamp
- Session keys use format: `{channel}:{chat_id}`

---

## ğŸ“ˆ Performance

Expected improvements over Python:

| Metric | Python | Rust | Improvement |
|--------|--------|------|-------------|
| **Binary Size** | ~50MB+ (venv) | ~10-15MB | 3-5x smaller |
| **Memory (idle)** | ~80-120MB | ~5-15MB | 10-50x less |
| **Startup Time** | ~2-3s | ~50-100ms | 20-30x faster |
| **Runtime Dep** | Python 3.11+, pip | None | Static binary |
| **Concurrency** | GIL-limited | True parallelism | Native async |

---

## ğŸ—ºï¸ Roadmap

### Phase 1: Core Foundation âœ… (Complete)
- Config, session, message bus
- LLM integration (rig-core)
- Tool system + basic tools
- Agent loop, context builder
- CLI (interactive mode)

### Phase 2: Full Agent Features âœ… (Delivered)
- Memory consolidation
- Skills loader
- Web tools (search, fetch)
- Subagent system
- Cron service + CLI commands
- Heartbeat

### Phase 3: Telegram + Gateway âœ… (Delivered)
- Channel trait + manager
- Telegram integration (teloxide)
- Gateway mode
- Slash commands

### Phase 4: Polish & Ship ğŸ“‹ (Planned)
- Onboarding wizard
- Error handling audit
- Testing (unit + integration)
- Binary packaging
- Cross-compilation

### Future: Additional Channels ğŸ”®
- Discord, Slack, Email
- Each channel is self-contained
- No core agent changes needed

---

## ğŸ¤ Contributing

PRs welcome! The codebase is designed to be clean and approachable.

### Development Guidelines

- **No backwards-compatibility hacks** â€” Delete unused code completely
- **Python compatibility where specified** â€” config.json and session JSONL must remain compatible
- **Modern Rust idioms** â€” Use current best practices
- **Clean refactoring** â€” Remove, don't comment out

### Useful Commands

```bash
# Format code
cargo fmt

# Lint
cargo clippy

# Check without building
cargo check

# Watch mode (install cargo-watch)
cargo watch -x check -x test -x run

# Documentation
cargo doc --open
```

Release and packaging notes live in `RELEASE.md`.

---

## ğŸ“œ License

MIT License â€” same as Python nanobot.

---

## ğŸ”— Links

- **Inspiration**: Inspired by the lightweight AI agent concept
- **GitHub Issues**: [Report issues and feature requests](https://github.com/HKUDS/nanobot/issues)

---

<p align="center">
  <sub>Built with Rust ğŸ¦€ for performance, safety, and developer experience</sub>
</p>
